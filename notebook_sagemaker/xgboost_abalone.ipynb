{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting abalone age with Amazon SageMaker and the XGBoost algorithm\n",
    "\n",
    "**Created by: [Tomas Beuzen](https://tomasbeuzen.github.io/). Hosted on [GitHub](xxx).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Contents\n",
    "1. [Introduction](#1)\n",
    "2. [Setup](#2)\n",
    "3. [Training the XGBoost model ](#3)\n",
    "4. [Create the model](#4)\n",
    "5. [Create endpoint](#5)\n",
    "6. [Validate the model for use](#6)\n",
    "7. [Delete Endpoint](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Introduction <a id=1></a>\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMakerâ€™s implementation of the XGBoost algorithm to train and host a regression model. It uses the classic abalone dataset which, the original version of which can be found [here](https://archive.ics.uci.edu/ml/datasets/abalone). Briefly, the number of \"rings\" present in an abalone shell is a proxy for the age of the abalone (age [years] = rings + 1.5). We aim to predict the age of abalone based on eight physical measurements. The data provided in the tutorial has been modified from the original, namely, the \"Sex\" characteristic has been one-hot-encoded and the \"rings\" target variable has had 1.5 added to it to represent the abalone age in years.\n",
    "\n",
    "This notebook is modified after the example provided by Amazon [here](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/xgboost_abalone/xgboost_abalone.ipynb). It has been significantly stripped down and modified to provide a bare minimum example illustrating how to build and deploy a model using SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Setup <a id=2></a>\n",
    "\n",
    "\n",
    "This notebook was created and tested on an ml.m2.medium notebook instance. The following code sets up paths to the S3 bucket we stored our data in previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "export AWS_REGION=us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "isConfigCell": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region name: us-east-1\n",
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "print(\"Region name: {}\".format(region))\n",
    "\n",
    "bucket_name = \"sagemakeruseast1\"  # <-- insert your bucket name here\n",
    "#bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region, bucket)\n",
    "\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    #if  my_region == 'us-east-1':\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemakeruseast1/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "bucket_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(bucket_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload files\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'output/abalone_train/abalone_train.csv')).upload_file('data/abalone_train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'output/abalone_validation/abalone_validation.csv')).upload_file('data/abalone_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Training the XGBoost model <a id=3></a>\n",
    "\n",
    "The following cell loads the Amazon sagemaker xgboost docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dir(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sets the parameters for, and executes training of the XGBoost model. You should not have to change any setting here (unless you want to change the name of the job which is clearly marked in a comment below). Training the model should take around 5 minutes. The code periodically pings the status of the job and prints the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job deploy-tutorial-2024-11-12-09-06-17\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "CPU times: user 97.2 ms, sys: 0 ns, total: 97.2 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = 'deploy-tutorial-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())  # <-- feel free to change the name of your job if you wish\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "create_training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": container,\n",
    "        \"TrainingInputMode\": \"File\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": bucket_path\n",
    "        # + \"/xgboost-model\"\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.m5.2xlarge\",\n",
    "        \"VolumeSizeInGB\": 5\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"silent\":\"0\",\n",
    "        \"objective\":\"reg:linear\",\n",
    "        \"num_round\":\"50\"\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 3600\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + '/abalone_train',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + '/abalone_validation',\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"text/csv\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "client = boto3.client('sagemaker', region_name=region)\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "import time\n",
    "\n",
    "status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print(status)\n",
    "while status !='Completed' and status!='Failed':\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message \"Completed\" that means training sucessfully completed and the output model was stored in the output path specified by `training_params['OutputDataConfig']` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create the model <a id=4></a>\n",
    "In order to set up hosting, we have to import the model from training to hosting. The cell below creates a SageMaker Model from the training output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy-tutorial-2024-11-12-09-06-17-model\n",
      "s3://sagemakeruseast1/xgboost-as-a-built-in-algo/output/deploy-tutorial-2024-11-12-09-06-17/output/model.tar.gz\n",
      "arn:aws:sagemaker:us-east-1:596676454538:model/deploy-tutorial-2024-11-12-09-06-17-model\n",
      "CPU times: user 23.7 ms, sys: 0 ns, total: 23.7 ms\n",
      "Wall time: 724 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name=job_name + '-model'\n",
    "print(model_name)\n",
    "\n",
    "info = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_data)\n",
    "\n",
    "primary_container = {\n",
    "    'Image': container,\n",
    "    'ModelDataUrl': model_data\n",
    "}\n",
    "\n",
    "create_model_response = client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Create endpoint <a id=5></a>\n",
    "\n",
    "Now that we've created a model we need to create a HTTPS endpoint where your machine learning model is available to provide inferences.\n",
    "\n",
    "### Create endpoint configuration\n",
    "SageMaker supports configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, we need to create an endpoint configuration which describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way. In addition, and more relevant for the current tutorial, the endpoint configuration describes the instance type required for model deployment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy-tutorial-2024-11-12-09-14-28\n",
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:596676454538:endpoint-config/deploy-tutorial-2024-11-12-09-14-28\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = 'deploy-tutorial-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response['EndpointConfigArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create endpoint\n",
    "Finally we will create the endpoint that serves up the model, using the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. It will take about 10 minutes to run the cell below and set up the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy-tutorial-2024-11-12-09-43-31\n",
      "arn:aws:sagemaker:us-east-1:596676454538:endpoint/deploy-tutorial-2024-11-12-09-43-31\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Arn: arn:aws:sagemaker:us-east-1:596676454538:endpoint/deploy-tutorial-2024-11-12-09-43-31\n",
      "Status: InService\n",
      "CPU times: user 102 ms, sys: 10.4 ms, total: 113 ms\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = 'deploy-tutorial-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])\n",
    "\n",
    "resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "while status=='Creating':\n",
    "    print(\"Status: \" + status)\n",
    "    time.sleep(60)\n",
    "    resp = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Validate the model for use <a id=6></a>\n",
    "Now that we've created the endpoint we can test that our model is available to perform inference. Let's try it out by making a single prediction which we call the \"payload\" in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,sex_I,sex_M\n",
      "0.41,0.325,0.1,0.3555,0.146,0.072,0.105,0,1\n",
      "Prediction: 10\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "features = 'length,diameter,height,whole_weight,shucked_weight,viscera_weight,shell_weight,sex_I,sex_M'\n",
    "payload = '0.41,0.325,0.1,0.3555,0.146,0.072,0.105,0,1'\n",
    "\n",
    "runtime_client = boto3.client('runtime.sagemaker', region_name=region)\n",
    "response = runtime_client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                   ContentType='text/csv', \n",
    "                                   Body=payload)\n",
    "result = response['Body'].read()\n",
    "result = result.decode(\"utf-8\")\n",
    "result = result.split(',')\n",
    "result = [math.ceil(float(i)) for i in result]\n",
    "print(features)\n",
    "print(payload)\n",
    "print (f'Prediction: {result[0]:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Delete Endpoint <a id=7></a>\n",
    "Once you are done using the endpoint, you can use the following to delete it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a7109ae2-a4c1-4ea4-bcb5-85f8204431eb',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a7109ae2-a4c1-4ea4-bcb5-85f8204431eb',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 12 Nov 2024 10:27:18 GMT',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
